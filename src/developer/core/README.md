# Core

Welcome to Pupil Core developer documentation. If you haven't already, we
highly recommend reading the [_Getting Started_](/core/#getting-started) section and the [_User Guide_](/core/software/pupil-capture.html), before continuing with the developer documentation.

Have a question? Get in touch with developers and other community members on the `#pupil-software-dev`
channel on [Discord](https://pupil-labs.com/chat).

<v-divider></v-divider>

## Overview
There are a number of ways you can interact with Pupil Core as a developer. 
- **Use the realtime API**: The Pupil Core [Network API](#network-api) allows you to remote control Pupil Core software and send/receive data realtime. It provides access to nearly all data generated by Pupil Core software: gaze, fixation, video data, and much more! The API can be used with any programming language that supports
[zeromq](https://zeromq.org/) and [msgpack](https://msgpack.org/).
- **Develop a plugin**: Pupil Core software is desgined with extendability in mind. It provides a simple yet powerful [Plugin API](#plugin-api) that is used by nearly all existing Pupil Core components. Develop a plugin when you need to access to data that is _not provided_ via the Network API.
- **Modify source code**: Can't do what you need to do with the network based API or plugin? Then get ready to dive into the inner workings of Pupil, set up dependencies, and [run from source](#running-from-source)!

::: tip
<v-icon large color="info">info_outline</v-icon>
In most cases you can simply [download Pupil Core app bundles](https://github.com/pupil-labs/pupil/releases/latest) and extend the functionality via API or Plugin. 
:::

### Terminology
There are a lot of new terms that are specific to eye and to Pupil Core. We have compiled a small list in the [terminology section](developer/core/terminology).


## Timing & Data Conventions
Pupil Capture is designed to work with multiple cameras that free-run at different
frame rates that may not be in sync. World and eye images are timestamped and any
resulting artifacts (detected pupil, markers, etc) inherit the source timestamp. Any
correlation of these data streams is the responsibility of the functional part that
needs the data to be correlated (e.g. calibration, visualization, analyses).

Example: Pupil Capture data format records the world video frames with their
respective timestamps. Independent of this, the recorder saves the detected gaze
and pupil positions at their own frame rate and with their timestamps. For details about
the stored data, see the [recording format](#recording-format) section.

Pupil Core software uses simple key-value structures to represent single data points.
Key-value structures can easily be serialized and nearly all programming languages have
an implementation for them.

Each data point should have at least two keys `topic` and `timestamp`. Each data point should be uniquely identifiable by its `topic` and `timestamp`.

1. `topic`: Identifies the type of the object. We recommend that you specify subtypes,
separated by a `.`
2. `timestamp`: [Pupil time](/developer/core/terminology#pupil-time) at which the datum was generated.

### Pupil Datum Format

The pupil detector generates `pupil` data from `eye` images. In addition to the `pupil`
topic and the `timestamp` (inherited from the eye image), the pupil detector adds fields most importantly:

- `norm_pos`: Pupil location in normalised eye coordinates, and
- `confidence`: Value indicating quality of the measurement

By default, the Pupil Core software uses the
[3d detector](/core/software/pupil-capture.html#pupil-detection) for pupil detection.
Since it is an extension of the 2d detector, its data contains keys that were
inherited from the 2d detection, as well as 3d detector specific keys. Below you can
see the Python representation of a 3d pupil datum:

```python
{  # pupil datum
'topic': 'pupil.0',
'method': '3d c++',
'norm_pos': [0.5, 0.5],  # norm space, [0, 1]
'diameter': 0.0,  # 2D image space, unit: pixel
'timestamp': 535741.715303987,  # time, unit: seconds
'confidence': 0.0,  # [0, 1]

# 2D ellipse of the pupil in image coordinates
'ellipse': {  # image space, unit: pixel
    'angle': 90.0,  # unit: degrees
    'center': [320.0, 240.0],
    'axes': [0.0, 0.0]},
'id': 0,  # eye id, 0 or 1

## 3D model data
# -1 means that the model is building up and has not finished fitting
'model_birth_timestamp': -1.0,
'model_confidence': 0.0,
'model_id': 1

# pupil polar coordinates on 3D eye model. The model assumes a fixed
# eye ball size. Therefore there is no `radius` key
'theta': 0,
'phi': 0,

# 3D pupil ellipse
'circle_3d': {  # 3D space, unit: mm
    'normal': [0.0, -0.0, 0.0],
    'radius': 0.0,
    'center': [0.0, -0.0, 0.0]},
'diameter_3d': 0.0,  # 3D space, unit: mm

# 3D eye ball sphere
'sphere': {  # 3D space, unit: mm
    'radius': 0.0,
    'center': [0.0, -0.0, 0.0]},
'projected_sphere': {  # image space, unit: pixel
    'angle': 90.0,
    'center': [0, 0],
    'axes': [0, 0]}}
```

### Gaze Datum Format

Gaza data is based on one (monocular) or two (binocular) pupil positions. The gaze
mapper is automatically setup after calibration and maps pupil positions into the world
camera coordinate system. The pupil data on which the gaze datum is based on can be
accessed using the `base_data` key.

```python
 {  # monocular gaze datum
    'topic': 'gaze.3d.1.',
    'confidence': 1.0,  # [0, 1]
    'norm_pos': [x, y],  # norm space, [0, 1]
    'timestamp': ts,  # time, unit: seconds

    # 3D space, unit: mm
    'gaze_normal_3d': [x, y, z],
    'eye_center_3d': [x, y, z],
    'gaze_point_3d': [x, y, z],
    'base_data': [<pupil datum>]  # list of pupil data used to calculate gaze
} 
```

```python
 {  # binocular gaze datum
    'topic': 'gaze.3d.01.',
    'confidence': 1.0,  # [0, 1]
    'norm_pos': [x, y],  # norm space, [0, 1]
    'timestamp': ts,  # time, unit: seconds

    # 3D space, unit: mm
    'gaze_normals_3d': {
        0: [x, y, z],
        1: [x, y, z],
    },
    'eye_centers_3d': {
        0: [x, y, z],
        1: [x, y, z],
    },
    'gaze_point_3d': [x, y, z],
    'base_data': [<pupil datum>]  # list of pupil data used to calculate gaze
}
```

<v-divider></v-divider>

## Network API

There are two different stages to the Pupil Core Network API:
1. **Pupil Remote**: Simple text-based API to remote control Pupil Core software.
2. **IPC Backbone**: [msgpack](https://msgpack.org/) based API with access to realtime data.

In the sections below, we outline how the basic communication works and how you can
access the different stages of the Network API.

### Basic Communication

All networking in the Pupil Core software is based on the [ZeroMQ](http://zeromq.org/)
network library. The following socket types are most often used in our networking schemes:
- [REQ-REP](http://zguide.zeromq.org/page:all#Ask-and-Ye-Shall-Receive), reliable one-to-one communication
- [PUB-SUB](http://zguide.zeromq.org/page:all#Getting-the-Message-Out), one-to-many communication

We highly recommend that you read [Chapter 2 of the ZeroMQ guide](http://zguide.zeromq.org/php:chapter2)
to get an intuition on the philosophy behind these socket types.

Pupil Core software uses the [pyzmq](https://github.com/zeromq/pyzmq) module, a
great Python ZeroMQ implementation. For auto-discovery of other Pupil devices in the
local network, we use [Pyre](https://github.com/zeromq/pyre).

### Pupil Remote

Pupil Remote provides a simple, text-based API to remote control the Pupil Core software,
as well as to access the second Network API stage (IPC backbone).

:::tip
<v-icon large color="info">info_outline</v-icon>
Pupil Remote accepts requests via a `REP` socket, by default on port `50020`.
Alternatively, you can provide a custom port via the `--port` application argument.
:::

To talk to Pupil Remote, open a `REQ` socket, connect to the specified port. Afterwards,
you can send simple text messages to control Pupil Capture and Pupil Service functions:

```py
'R'  # start recording with auto generated session name
'R rec_name'  # start recording named "rec_name" 
'r'  # stop recording
'C'  # start currently selected calibration
'c'  # stop currently selected calibration
'T 1234.56'  # resets current Pupil time to given timestamp
't'  # get current Pupil time; returns a float as string.
'v'  # get the Pupil Core software version string

# IPC Backbone communication
'PUB_PORT'  # return the current pub port of the IPC Backbone
'SUB_PORT'  # return the current sub port of the IPC Backbone
```

::: warning
<v-icon large color="warning">info_outline</v-icon>
For every message that you send to Pupil Remote, you need to receive the response. If
you do not call `recv()`, Pupil Capture might become unresponsive!
:::

::: tip
<v-icon large color="info">info_outline</v-icon>
Pupil Service does not support the creation of recordings, i.e. the `R` and `r` commands
do not work with Pupil Service.
:::

See this [Python script](https://github.com/pupil-labs/pupil-helpers/blob/master/python/pupil_remote_control.py)
for an example interaction with Pupil Remote.

### IPC Backbone

The IPC Backbone, the second stage of the Network API, grants you realtime access to
nearly all data generated by Pupil Capture and Pupil Service.

If you want to tap into the IPC backbone you will not only need the IP address but also
the session's unique port. You can request them from `Pupil Remote`:

```python
import zmq
ctx = zmq.Context()
# The REQ talks to Pupil remote and receives the session unique IPC SUB PORT
requester = ctx.socket(zmq.REQ)

ip = 'localhost'  # If you talk to a different machine use its IP.
port = 50020  # The port defaults to 50020. Set in Pupil Capture GUI.

requester.connect('tcp://%s:%s'%(ip,port))
requester.send_string('SUB_PORT')
sub_port = requester.recv_string()
```

Before you can proceed to [send](#writing-to-the-ipc-backbone) and
[receive](#reading-from-the-ipc-backbone) data, you need to understand the message
format used by the IPC Backbone, which is explained in the next section.

### IPC Backbone Message Format
All messages on the IPC Backbone are multipart messages containing (at least) two message frames:

 - `Frame 1` contains the [topic](#timing-data-conventions) string, e.g. `pupil.0`, `logging.info`,
`notify.recording.has_started`

 - `Frame 2` contains a [`msgpack`](https://msgpack.org/) encoded key-value mapping.
This is the actual [message](#timing-data-conventions). We choose `msgpack` as the
serializer due to its efficient format (45% smaller than `json`, 200% faster than
`ujson`) and because encoders exist for almost every language.

#### Message Topics
Messages can have any topic chosen by the user. See topics below for a list of message types used by Pupil apps.

#### Pupil and Gaze Messages

Pupil data is sent from the eye0 and eye1 process with the topic `pupil.0` or `pupil.1`.
Gaze mappers receive this data and publish messages with topic `gaze`. See the
[Timing & Data Conventions](#pupil-datum-format) section for example messages for the
`pupil` and `gaze` topics.

#### Notification Message
Pupil uses special messages called `notifications` to coordinate all activities.
Notifications are key-value mappings with the required field `subject`. Subjects are
grouped by categories `category.command_or_statement`. Example: `recording.should_stop`.

```python
# message topic:
'notify.recording.should_start'
# message payload, a notification dict
{'subject':'recording.should_start', 'session_name':'my session'}
```

The message topic construction:

```python
topic = f"notify.{notification['subject']}"
```

You should use the `notification` topic for coordination with the app. All notifications
on the IPC Backbone are automatically made available to all plugins in their `on_notify`
callback and used in all Pupil apps.

**TODO: Link on_notify docs**

In stark contrast to gaze and pupil, the notify topic should **not** be used at high volume. If you find that you need to write more than 10 messages a second, it is probably not a notification but another kind of data. Make a custom topic instead.

```python
import zmq
import msgpack

topic = 'your_custom_topic'
payload = {'topic': topic}

# create and connect PUB socket to IPC
pub_socket = zmq.Socket(zmq.Context(), zmq.PUB)
pub_socket.connect(ipc_pub_url)

# send payload using custom topic
socket.send_string(topic, flags=zmq.SNDMORE)
socket.send(msgpack.dumps(payload, use_bin_type=True))
```

The script above requires you to implement a custom [Plugin](#plugin-api) to process the
incoming messages. Alternatively, you can use remote annotations.

#### Remote Annotations
You can also create [annotation](/core/software/pupil-capture.html#annotations) events
programmatically and send them using the IPC, or by sending messages to the Pupil Remote interface. Here is an example annotation notification.

```python
{
    'subject': "annotation",
    'label': "Hi this is my annotation 1",
    'timestamp': <pupil time>,
    'duration': 1.0,
    'source': 'a test script',
    'record': True
}
```

::: tip
<v-icon large color="info">info_outline</v-icon>
<a href="https://github.com/pupil-labs/pupil-helpers/blob/master/pupil_remote/remote_annotations.py" title="remote annotation script">This script</a> demonstrates how to send remote annotations. Use this script as a starting point for your integrations.
:::

#### Log Messages


The topic is `logging.log_level_name` (debug, info, warning, error,...). The message is a
key-value mapping that contains all attributes of the python `logging.record` instance.

```python
# message topic:
'logging.warning'
# message payload, logging record attributes as dict:
{
    'levelname': 'WARNING',
    'msg': 'Process started.',
    'name': 'eye',
    ...
}
```

### Reading from the IPC Backbone

Now that we know what data format to expect, we can start reading the data from the IPC
Backbone. In order to be able to subscribe to the IPC Backbone, we need to request the
subscription port from Pupil Remote, [as demonstrated above](#second-stage-ipc-backbone).

Subscribe to desired topics and receive all relevant messages (i.e. messages whose topic
prefix matches the subscription). Be aware that the IPC Backbone can carry a lot of data.
Do not subscribe to the whole stream unless you know that your code can drink from a
firehose. (If it can not, you become `the snail`, see [Delivery Guarantees PUB-SUB](#delivery-guarantees-pub-sub).)

```python
#...continued from above
# Assumes `sub_port` to be set to the current subscription port
subscriber = ctx.socket(zmq.SUB)
subscriber.connect('tcp://%s:%s'%(ip, sub_port))
subscriber.set(zmq.SUBSCRIBE, 'notify.')  # receive all notification messages
subscriber.set(zmq.SUBSCRIBE, 'logging.error')  #receive logging error messages
# subscriber.set(zmq.SUBSCRIBE, '')  #r eceive everything (don't do this)
# you can setup multiple subscriber sockets
# Sockets can be polled or read in different threads.

# we need a serializer
import msgpack as serializer

while True:
    topic,payload = subscriber.recv_multipart()
    message = serializer.loads(payload)
    print topic,':',message
```

### Writing to the IPC Backbone

You can send notifications to the IPC Backbone for everybody to read as well. Pupil
Remote acts as an intermediary for reliable transport:

```python
# continued from above
import msgpack as serializer
notification = {'subject':'recording.should_start', 'session_name':'my session'}
topic = 'notify.' + notification['subject']
payload = serializer.dumps(notification)
requester.send_string(topic, flags=zmq.SNDMORE)
requester.send(payload)
print(requester.recv_string())
```

We say reliable transport because Pupil Remote will confirm every notification we send
with 'Notification received'. When we get this message we have a guarantee that the
notification was received by the Pupil Core software.

If we listen to the backbone using our subscriber from above, we will see the message
again because we have subscribed to all notifications.

#### Writing to the Backbone directly

If you want to write messages other than notifications onto the IPC backbone, you can
publish to the bus directly. Because this uses a PUB socket, you should read up on
[Delivery Guarantees PUB-SUB](#delivery-guarantees-pub-sub) below.

```python
# continued from above
from time import time, sleep

requester.send_string('PUB_PORT')
pub_port = requester.recv_string()
publisher = ctx.socket(zmq.PUB)
publisher.connect('tcp://%s:%s'%(ip, pub_port))
sleep(1)  # see Async connect in the paragraphs below
notification = {'subject':'calibration.should_start'}
topic = 'notify.' + notification['subject']
payload = serializer.dumps(notification)
publisher.send_string(topic, flags=zmq.SNDMORE)
publisher.send(payload)
```

### IPC Backbone Implementation

This section provides detailed inside information about the IPC Backbone implementation.
Please see specifically the subsection about [delivery guarantees](#delivery-guarantees-zmq).

Pupil Core software uses a PUB-SUB Proxy as their messaging bus. We call it the
`IPC Backbone`. The IPC Backbone runs as a thread in the main process. It is basically a
big message relay station. Actors can push messages into it and subscribe to other
actors' messages. Therefore, it is the backbone of all communication to/from and
within the Pupil Core software.

::: tip
<v-icon large color="info">info_outline</v-icon>
Note - The main process does not do any CPU heavy work. It only runs the proxy, launches
other processes and does a few other light tasks.
:::

#### IPC Backbone used by Pupil Capture and Service
The IPC Backbone has a `SUB` and a `PUB` address. Both are bound to a random port on app
launch and are known to all components of the app. All processes and threads within the
app use the IPC Backbone to communicate.
 - Using a `ZMQ PUB` socket, other actors in the app connect to the `pub_port` of the
 Backbone and publish messages to the IPC Backbone. (For important low volume msgs a
 PUSH socket is also supported.)
 - Using a `ZMQ SUB` socket, other actors connect to the `sub_port` of the Backbone to
 subscribe to parts of the message stream.

Example: The eye process sends pupil data onto the IPC Backbone. The gaze mappers in
the world process receive this data, generate gaze data and publish it on the IPC
Backbone. World, Launcher, and Eye exchange control messages on the bus for coordination.

#### Delivery guarantees ZMQ
ZMQ is a great abstraction for us. It is super fast, has a multitude of language bindings
and solves a lot of the nitty-gritty networking problems we don't want to deal with. As
our short description of ZMQ does not do ZMQ any justice, we recommend reading the
[ZMQ guide](http://zguide.zeromq.org/page:all) if you have the time. Below are some
insights from the guide that are relevant for our use cases.

 - Messages are guaranteed to be delivered whole or not at all.
 - Unlike bare TCP it is ok to connect before binding.
 - ZMQ will try to repair broken connections in the background for us.
 - It will deal with a lot of low level tcp handling so we don't have to.

#### Delivery Guarantees PUB-SUB

ZMQ PUB SUB will make no guarantees for delivery. Reasons for not receiving messages are:

 - `Async Connect`/`The Late joiner`: PUB sockets drop messages before a connection has
 been established and topics subscribed. ZMQ connects asynchronously in the background.
 - `The Snail`: If SUB sockets do not consume delivered messages fast enough they start dropping them.
 - `Fast close`: A PUB socket may loose packages if you close it right after sending. 

For more information see [ZMQ Guide Chapter 5 - Advanced Pub-Sub Patterns](http://zguide.zeromq.org/php:chapter5).

:::tip
<v-icon large color="info">info_outline</v-icon>
In order to avoid accidentally dropping notifications in Pupil, we use a `PUSH` instead
of an `PUB` socket. It acts as an intermediary for notifications and guarantees that any
notification sent to the IPC Backbone, is processed and published by it.
:::

#### Delivery Guarantees REQ-REP
When writing to the Backbone via REQ-REP we will get confirmations/replies for every
message sent. Since REPREQ requires lockstep communication that is always initiated from
the actor connecting to Pupil Capture/Service. It does not suffer the above issues.

#### Delivery Guarantees in general
We use TCP in ZMQ, it is generally a reliable transport. The app communicates to the IPC
Backbone via localhost loopback, this is *very* reliable. We have not been able to
produce a dropped message for network reasons on localhost.

However, unreliable, congested networks (e.g. wifi with many actors) can cause problems
when talking and listening to Pupil Capture/Service from a different machine. If using a
unreliable network we will need to design our scripts and apps so that interfaces are
able to deal with dropped messages.

#### Latency
Latency is bound by the latency of the network. On the same machine we can use the
loopback interface (localhost) and do a quick test to understand delay and jitter of
Pupil Remote requests...

```python
# continued from above
ts = []
for x in range(100):
    sleep(0.003) #simulate spaced requests as in real world
    t = time()
    requester.send_string('t')
    requester.recv_string()
    ts.append(time()-t)
print(min(ts), sum(ts)/len(ts), max(ts))
>>> 0.000266075134277 0.000597472190857 0.00339102745056
```
... and when talking directly to the IPC backbone and waiting for the same message to
appear to the subscriber:

```python
# continued from above
monitor = Msg_Receiver(ctx, sub_url, topics=('notify.pingback_test',))
sleep(1.)

ts = []
for x in range(100):
    sleep(0.003)  #simulate spaced requests as in real world
    t = time()
    #notify is a method of the Msg_Dispatcher class in zmq_tools.py
    notification = {'subject':'pingback_test'}
    topic = 'notify.' + notification['subject']
    payload = serializer.dumps(notification)
    publisher.send_string(topic, flags=zmq.SNDMORE)
    publisher.send(payload)
    monitor.recv()
    ts.append(time()-t)
print(min(ts), sum(ts)/len(ts) , max(ts))
>>>0.000180959701538 0.000300960540771 0.000565052032471
```

#### Throughput
During a test we have run dual 120fps eye tracking with a dummy gaze mapper that turned
every pupil datum into a gaze datum. This is effectively 480 messages/sec. The main
process running the `IPC backbone proxy` showed a cpu load of `3%` on a MacBook Air
(late 2012).

Artificially increasing the pupil messages by a factor 100 increases the message load to
24.000 pupil messages/sec. At this rate the gaze mapper cannot keep up but the
`IPC backbone proxy` runs at only `38%` cpu load.

It appears ZMQ is indeed highly optimized for speed.

<!-- this is a horizontal divider -->
<v-divider></v-divider>

## Recording Format

This section outlines the Pupil Player recording format. We recommend reading it
thourougly if you want to develop software that creates recordings on its own,
or processes existing recordings without having to open them in Pupil Player.

### Meta Files

Meta files are essential for Pupil Player. Without them, Pupil Player is not able to
recognize a directory as a Pupil Recording. 

The [Pupil Player Recording Format 2.0](https://github.com/pupil-labs/pupil/blob/master/pupil_src/shared_modules/pupil_recording/README.md)—introduced in version `v1.16`—requires the meta info file to be named `info.player.json`.
See its [specification](https://github.com/pupil-labs/pupil/blob/master/pupil_src/shared_modules/pupil_recording/README.md) for details.

::: tip
<v-icon large color="info">info_outline</v-icon>
Pupil Mobile and Pupil Invisible recordings have their own meta file definitions:
`info.csv` and `info.json`. When opened in Pupil Player, the meta info file
will be transformed the Pupil Player Recording Format 2.0.
:::

### Timestamp Files
Timestamp files must follow this strict naming convention:
Given that a data file is named `<name>.<ext>` then its timestamps file has to be named `<name>_timestamps.npy`.

Timestamp files are saved in the [NPY binary format](https://docs.scipy.org/doc/numpy/neps/npy-format.html). You can use [`numpy.load()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load) to access the timestamps in Python.

A datum and its timestamp have the same index within their respective files, i.e. the `i`th timestamp in `world_timestamps.npy` belongs to the `i`th video frame in `world.mp4`.

### Video Files
Video files are only recognized if they comply with the following constraints:

Allowed video file extentions are:

- `.mp4`
- `.mkv`
- `.avi`
- `.h264`
- `.mjpeg`

Allowed video file names are:

- `world`: Scene video
- `eye0`: Right eye video
- `eye1`: Left eye video

The video files should look like:

- `world.mp4`, `eye0.mjpeg`, `eye1.mjpeg`

We also support multiple parts of video files as input. For instance:

- `world.mp4`, `world_001.mp4`, `world_002.mp4`, ...
- `eye0.mjpeg`, `eye0_001.mjpeg`

And their corresponding timestamp files should follow the pattern:

- `world_timestamps.npy`, `world_001_timestamps.npy`, `world_002_timestamps.npy`, ...

### Audio File
An audio file is only recognized in Pupil Player's playback plugin if the file is named
`audio.mp4` and there is a corresponding `audio_timestamps.npy` file containing the
correct audio timestamps.

### `pldata` Files
These files contain a sequence of independently msgpack-encoded messages. Each message consists of two frames:
1. frame: The payload's topic as a string, e.g. `"pupil.0"`
2. frame: The payload, e.g. a pupil datum, encoded as msgpack

For clarification: The second frame is encoded twice!

Pupil Player decodes the messages into [`file_methods.Serialized_Dict`](https://github.com/pupil-labs/pupil/blob/315188dcfba9bef02a5b1d9a3770929d7510ae2f/pupil_src/shared_modules/file_methods.py#L209)s. Each `Serialized_Dict` instance holds the serialized second frame and is responsible for decoding it on demand. The class is designed such that there is a maximum number of decoded frames at the same time. This prevents Pupil Player from using excessive amounts of memory.

You can use [`file_methods.PLData_Writer`](https://github.com/pupil-labs/pupil/blob/315188dcfba9bef02a5b1d9a3770929d7510ae2f/pupil_src/shared_modules/file_methods.py#L138) and [`file_methods.load_pldata_file()`](https://github.com/pupil-labs/pupil/blob/315188dcfba9bef02a5b1d9a3770929d7510ae2f/pupil_src/shared_modules/file_methods.py#L111) to read and write `pldata` files.

### Other Files
Files without file extention, e.g. the deprecated `pupil_data` file, and files with a `.meta` extention are msgpack-encoded dictionaries. They can be read and written using [`file_methods.load_object()` and `file_methods.save_object()`](https://github.com/pupil-labs/pupil/blob/315188dcfba9bef02a5b1d9a3770929d7510ae2f/pupil_src/shared_modules/file_methods.py#L57-L87) and do *not* have a corresponding timestamps file.

<!-- this is a horizontal divider -->
<v-divider></v-divider>

## Plugin API

Overview of language, code structure, and general conventions

### Language
Pupil is written in `Python 3`, but no "heavy lifting" is done in Python. High performance computer vision, media compression, display libraries, and custom functions are written in external libraries or c/c++ and accessed though [cython](http://cython.org/). Python plays the role of "glue" that sticks all the pieces together.

We also like writing code in Python because it's *quick and easy* to move from initial idea to working proof-of-concept. If proof-of-concept code is slow, optimization and performance enhancement can happen in iterations of code.

### Process Structure
When Pupil Capture starts, in default settings two processes are spawned:

**[Eye](https://github.com/pupil-labs/pupil/blob/master/pupil_src/launchables/eye.py)** and **[World](https://github.com/pupil-labs/pupil/blob/master/pupil_src/launchables/world.py)**. Both processes grab image frames from a video capture stream but they have very different tasks.

### Eye Process
The eye process only has one purpose - to detect the pupil and broadcast its position. The process breakdown looks like this:

* Grabs eye camera images from eye camera video stream
* Find the pupil position in the image
* Broadcast/stream the detected pupil position.

<aside class="notice">
Note - Pupil position refers to the position of the pupil in the eye camera space. This is different from gaze position which is what we call the mapped pupil positions in the world camera space.
</aside>

### World Process
This is the workhorse.

* Grabs the world camera images from the world camera video stream
* Receives pupil positions from the eye process
* Performs calibration mapping from pupil positions to gaze positions
* Loads plugins - to detect fixations, track surfaces, and more...
* Records video and data.
Most, and preferably all coordination and control happens within the World process.

## Running From Source

Follow the setup instructions for your OS on the Pupil Core [Github repo](https://github.com/pupil-labs/pupil)
